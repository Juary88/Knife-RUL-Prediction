{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from kesmarag.swpt import SWPT\n",
    "from scipy import stats\n",
    "from scipy.signal import impulse2\n",
    "from util import calc_crest_factor\n",
    "import seaborn as sns\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "# max_features = 8\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(id, length, dim, is_fft=False):\n",
    "    kurtosis = []\n",
    "    skew = []\n",
    "    variance = []\n",
    "    denominator = []\n",
    "    maxs = []\n",
    "    for j in range(1, length):\n",
    "        data = pd.read_csv(\"train/{}/Sensor/{}.csv\".format(id, j + 1)).values\n",
    "        x = data[:, dim]\n",
    "        # z = data[:, 1]\n",
    "        # y = data[:, 2]\n",
    "        if is_fft:\n",
    "            x = np.fft.fft(x)\n",
    "        i = 0\n",
    "        while (i + 1) * 256000 < len(x) - 256000:\n",
    "            k = stats.kurtosis(x[i * 256000: (i + 1) * 256000])\n",
    "            kurtosis.append(k)\n",
    "            s = stats.skew(x[i * 256000: (i + 1) * 256000])\n",
    "            \n",
    "            skew.append(s)\n",
    "            v = x[i * 256000: (i + 1) * 256000].var()\n",
    "            variance.append(v)\n",
    "\n",
    "            vs = x[i * 256000: (i + 1) * 256000]\n",
    "            sum = 0.0\n",
    "            for v in vs:\n",
    "                sum += v * v\n",
    "            denominator.append(sum / len(vs))\n",
    "            \n",
    "            m = x[i* 256000: (i + 1) * 256000].max()\n",
    "            maxs.append(m)\n",
    "\n",
    "            i = i + 1\n",
    "        k = stats.kurtosis(x[i * 256000:])\n",
    "        kurtosis.append(k)\n",
    "        s = stats.skew(x[i * 256000:])\n",
    "        skew.append(s)\n",
    "        v = x[i*256000:].var()\n",
    "        variance.append(v)\n",
    "        vs = x[i * 256000:]\n",
    "        sum = 0.0\n",
    "        for v in vs:\n",
    "            sum += v * v\n",
    "        denominator.append(sum / len(vs))\n",
    "        m = x[i * 256000:].max()\n",
    "        maxs.append(m)\n",
    "        \n",
    "#     data = np.array((kurtosis, skew, variance, denominator))\n",
    "#     print(data.shape)\n",
    "    return np.array((kurtosis, skew, variance, denominator, maxs)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x_1_t = features('01', 47, 0, False)\n",
    "data_x_1_f = features('01', 47, 0, True)\n",
    "data_1 = np.concatenate((data_x_1_t, data_x_1_f), axis=1)\n",
    "\n",
    "data_x_2_t = features('02', 47, 0, False)\n",
    "data_x_2_f = features('02', 47, 0, True)\n",
    "data_2 = np.concatenate((data_x_2_t, data_x_2_f), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = np.concatenate((data_1, data_2), axis=0)\n",
    "train_data = data_x_1_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = data_x_1_t[:,0]\n",
    "index = [i for i in range(len(tmp))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.19524717  1.3179095   1.40394873  1.46368238  1.26727321  0.79019294\n",
      "  1.39096502  2.01139835  2.10317529  0.93712144  1.06287118  1.69144536\n",
      "  1.52605102  1.70019456  1.59512417  2.13827669  0.8786993   0.91588916\n",
      "  1.50735263  1.16137538  1.57222903  1.50424578  2.04466811  1.24912184\n",
      "  1.3406418   1.69524489  1.14655496  1.84958348  1.57176052  1.63671809\n",
      "  1.10607904  1.40816515  1.3645916   1.5288441   1.556423    1.25018233\n",
      "  1.78803452  1.23318593  1.41797374  1.37828854  1.7281156   1.15132773\n",
      "  1.31391866  1.92978944  1.25925714  1.43516356  1.6136155   2.57576283\n",
      "  1.30061582  1.21248443  1.62671188  1.79486459  1.47484235  1.62142862\n",
      "  2.59379703  1.60302948  1.16607471  1.77123209  1.93831466  1.79617096\n",
      "  2.01308539  1.73579882  2.02350355  1.24253336  1.5826339   1.89124642\n",
      "  2.232972    2.41442507  2.10918221  2.67249325  1.66778746  1.97880126\n",
      "  2.33063687  2.11471376  2.61591242  2.25951006  2.77066709  1.6175397\n",
      "  1.69866267  1.63980861  2.10939513  1.87823075  2.24135025  2.75490981\n",
      "  1.55866001  1.87827879  1.80128691  1.73351647  2.7700318   1.96321326\n",
      "  3.27059708  1.88065476  2.13185537  1.85087968  2.50751217  2.62859414\n",
      "  2.80669028  1.87399559  1.47308589  2.08486508  1.71269095  2.14012739\n",
      "  2.39299842  2.14222936  2.02207463  1.57001584  2.55929115  1.78794187\n",
      "  1.68179116  2.29235047  2.33565145  1.94290154  2.02580541  1.84521723\n",
      "  2.17625754  2.25125643  1.9598016   1.67009227  2.26289195  2.42109619\n",
      "  2.29772819  1.74954401  2.31442969  3.18194092  1.32674308  2.09283747\n",
      "  2.26921803  1.62272958  2.13883092  1.64831514  2.48230086  1.61846661\n",
      "  2.0432392   2.1059872   2.15576646  1.86323254  2.32911399  2.00308557\n",
      "  2.31977967  1.81134165  1.76049452  1.88362854  1.64619671  2.02725982\n",
      "  2.1860783   1.7046032   2.27278384  1.40543902  2.07274844  1.52106508\n",
      "  2.06381484  2.00330803  1.52118213  1.93955095  1.80539274  1.54623273\n",
      "  1.2452351   1.69101418  1.81162186  1.83300503  1.93644967  1.53577403\n",
      "  1.7629869   1.26106775  1.60178607  2.07063741  1.76848758  1.32502858\n",
      "  1.61459026  2.06494673  1.24210263  1.19734853  2.39488579  1.66213875\n",
      "  1.28817963  1.26492586  2.01527808  1.23850208  1.72187643  1.12317146\n",
      "  1.90772217  1.47842066  1.30175221  1.29424575  1.23925273  1.5656765\n",
      "  2.00084276  1.36886886  1.27037378  1.07741676  1.32617465  1.43191555\n",
      "  1.4698807   1.26329807  1.36228757  1.31625681  1.28920813  1.62553325\n",
      "  1.25064588  1.63374328  1.2578581   1.59358688  0.81961273  0.90955384\n",
      "  1.08711136  1.15961351  0.93046507  1.03605004  1.87628964  0.79138343\n",
      "  2.77274003  1.30923449  1.35486362  1.54343064  0.8045712   1.35447725\n",
      "  1.75079374  1.94198756  1.70891229  0.13864655  1.16013682  1.76501227\n",
      "  1.04670837  1.70670376  1.3541909   2.67566554  1.26590549  1.52333261\n",
      "  1.94135818  1.48667026  1.52553809  1.27165625  1.88336495  1.77186909\n",
      "  1.60900395  1.4860277   1.61219971  2.55836969  1.50015187  1.49273421\n",
      "  1.88887213  1.39077258  1.15116084  1.34069589  1.45883323  1.59014383\n",
      "  1.43489379  3.81794529  3.04706861  1.21496988  1.27693878  1.57713608\n",
      "  1.29605114  1.04061865  1.14950955  1.7920246   1.41203361  1.52340076\n",
      "  1.4340554   3.28192394  2.20383048  1.10901773  1.09405415  1.26141315\n",
      "  1.04093688]\n"
     ]
    }
   ],
   "source": [
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(265, 4)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yuanli\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train_data = train_data\n",
    "train_data = train_data.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = [i for i in range(data_1.shape[0])]\n",
    "# for i in range(data_2.shape[0]):\n",
    "#     train_label.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x_3_t = features('03', 36, 0, False)\n",
    "data_x_3_f = features('03', 36, 0, True)\n",
    "# test_data = np.concatenate((data_x_3_t, data_x_3_f), axis=1)\n",
    "test_data = data_x_3_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yuanli\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "test_data = test_data\n",
    "test_data = test_data.astype(np.float64)\n",
    "test_label = [i for i in range(test_data.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208, 4)\n"
     ]
    }
   ],
   "source": [
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=0.1,\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [1.0, 10.0, 100.0, 1000.0], 'gamma': array([  1.00000e-02,   1.00000e-01,   1.00000e+00,   1.00000e+01,\n",
       "         1.00000e+02])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr = GridSearchCV(SVR(kernel='rbf', gamma=0.1), cv=5,\n",
    "                   param_grid={\"C\": [1e0, 1e1, 1e2, 1e3],\n",
    "                               \"gamma\": np.logspace(-2, 2, 5)})\n",
    "svr.fit(train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=KernelRidge(alpha=1, coef0=1, degree=3, gamma=0.1, kernel='rbf',\n",
       "      kernel_params=None),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'alpha': [1.0, 0.1, 0.01, 0.001], 'gamma': array([  1.00000e-02,   1.00000e-01,   1.00000e+00,   1.00000e+01,\n",
       "         1.00000e+02])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kr = GridSearchCV(KernelRidge(kernel='rbf', gamma=0.1), cv=5,\n",
    "                  param_grid={\"alpha\": [1e0, 0.1, 1e-2, 1e-3],\n",
    "                              \"gamma\": np.logspace(-2, 2, 5)})\n",
    "kr.fit(train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "pre = kr.predict(test_data)\n",
    "print(pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = max(train_data.max(), test_data.max())\n",
    "print(type(max_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(int(max_features), 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(train_data, train_label,\n",
    "          batch_size=batch_size,\n",
    "          epochs=15,\n",
    "          validation_data=(test_data, test_label))\n",
    "score, acc = model.evaluate(test_data, test_label,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
