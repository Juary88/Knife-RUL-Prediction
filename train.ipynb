{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from kesmarag.swpt import SWPT\n",
    "from scipy import stats\n",
    "from scipy.signal import impulse2\n",
    "from util import calc_crest_factor\n",
    "import seaborn as sns\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "# max_features = 8\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features(id, length, dim, is_fft=False):\n",
    "    kurtosis = []\n",
    "    skew = []\n",
    "    variance = []\n",
    "    denominator = []\n",
    "    maxs = []\n",
    "    for j in range(1, length):\n",
    "        data = pd.read_csv(\"train/{}/Sensor/{}.csv\".format(id, j + 1)).values\n",
    "        x = data[:, dim]\n",
    "        # z = data[:, 1]\n",
    "        # y = data[:, 2]\n",
    "        if is_fft:\n",
    "            x = np.fft.fft(x)\n",
    "        i = 0\n",
    "        while (i + 1) * 256000 < len(x) - 256000:\n",
    "            k = stats.kurtosis(x[i * 256000: (i + 1) * 256000])\n",
    "            kurtosis.append(k)\n",
    "            s = stats.skew(x[i * 256000: (i + 1) * 256000])\n",
    "            \n",
    "            skew.append(s)\n",
    "            v = x[i * 256000: (i + 1) * 256000].var()\n",
    "            variance.append(v)\n",
    "\n",
    "            vs = x[i * 256000: (i + 1) * 256000]\n",
    "            sum = 0.0\n",
    "            for v in vs:\n",
    "                sum += v * v\n",
    "            denominator.append(sum / len(vs))\n",
    "            \n",
    "            m = x[i* 256000: (i + 1) * 256000].max()\n",
    "            maxs.append(m)\n",
    "\n",
    "            i = i + 1\n",
    "        k = stats.kurtosis(x[i * 256000:])\n",
    "        kurtosis.append(k)\n",
    "        s = stats.skew(x[i * 256000:])\n",
    "        skew.append(s)\n",
    "        v = x[i*256000:].var()\n",
    "        variance.append(v)\n",
    "        vs = x[i * 256000:]\n",
    "        sum = 0.0\n",
    "        for v in vs:\n",
    "            sum += v * v\n",
    "        denominator.append(sum / len(vs))\n",
    "        m = x[i * 256000:].max()\n",
    "        maxs.append(m)\n",
    "        \n",
    "#     data = np.array((kurtosis, skew, variance, denominator))\n",
    "#     print(data.shape)\n",
    "    return np.array((kurtosis, skew, variance, denominator, maxs)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x_1_t = features('01', 47, 0, False)\n",
    "data_x_1_f = features('01', 47, 0, True)\n",
    "data_1 = np.concatenate((data_x_1_t, data_x_1_f), axis=1)\n",
    "\n",
    "data_x_2_t = features('02', 47, 0, False)\n",
    "data_x_2_f = features('02', 47, 0, True)\n",
    "data_2 = np.concatenate((data_x_2_t, data_x_2_f), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = np.concatenate((data_1, data_2), axis=0)\n",
    "train_data = data_x_1_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(265, 4)\n"
     ]
    }
   ],
   "source": [
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yuanli\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train_data = train_data\n",
    "train_data = train_data.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = [i for i in range(data_1.shape[0])]\n",
    "# for i in range(data_2.shape[0]):\n",
    "#     train_label.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x_3_t = features('03', 36, 0, False)\n",
    "data_x_3_f = features('03', 36, 0, True)\n",
    "# test_data = np.concatenate((data_x_3_t, data_x_3_f), axis=1)\n",
    "test_data = data_x_3_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yuanli\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "test_data = test_data\n",
    "test_data = test_data.astype(np.float64)\n",
    "test_label = [i for i in range(test_data.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(208, 4)\n"
     ]
    }
   ],
   "source": [
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=0.1,\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [1.0, 10.0, 100.0, 1000.0], 'gamma': array([  1.00000e-02,   1.00000e-01,   1.00000e+00,   1.00000e+01,\n",
       "         1.00000e+02])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr = GridSearchCV(SVR(kernel='rbf', gamma=0.1), cv=5,\n",
    "                   param_grid={\"C\": [1e0, 1e1, 1e2, 1e3],\n",
    "                               \"gamma\": np.logspace(-2, 2, 5)})\n",
    "svr.fit(train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=KernelRidge(alpha=1, coef0=1, degree=3, gamma=0.1, kernel='rbf',\n",
       "      kernel_params=None),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'alpha': [1.0, 0.1, 0.01, 0.001], 'gamma': array([  1.00000e-02,   1.00000e-01,   1.00000e+00,   1.00000e+01,\n",
       "         1.00000e+02])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kr = GridSearchCV(KernelRidge(kernel='rbf', gamma=0.1), cv=5,\n",
    "                  param_grid={\"alpha\": [1e0, 0.1, 1e-2, 1e-3],\n",
    "                              \"gamma\": np.logspace(-2, 2, 5)})\n",
    "kr.fit(train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "pre = kr.predict(test_data)\n",
    "print(pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = max(train_data.max(), test_data.max())\n",
    "print(type(max_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(int(max_features), 128))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(train_data, train_label,\n",
    "          batch_size=batch_size,\n",
    "          epochs=15,\n",
    "          validation_data=(test_data, test_label))\n",
    "score, acc = model.evaluate(test_data, test_label,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
